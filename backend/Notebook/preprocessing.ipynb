{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in c:\\users\\zohai\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in c:\\users\\zohai\\anaconda3\\lib\\site-packages (from thefuzz) (3.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c645b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from thefuzz import process  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22e665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c89f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \" \", text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # stopword remove\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]   # lemmatize\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34814d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/coursera_course_dataset_v3.csv\")\n",
    "df = df.drop(columns=['unnamed:_0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d984fa8",
   "metadata": {},
   "source": [
    "Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f36ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Title', 'Organization', 'Skills', 'course_description', 'Difficulty', 'Type', 'Duration']\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "    df[col] = df[col].str.replace(\"Ã‚\", \"\", regex=False).str.strip()\n",
    "    df[col] = df[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b847571",
   "metadata": {},
   "source": [
    "Numeric Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['course_students_enrolled'] = df['course_students_enrolled'].astype(str).str.replace(',', '', regex=False)\n",
    "df['course_students_enrolled'] = pd.to_numeric(df['course_students_enrolled'], errors='coerce')\n",
    "df['course_students_enrolled'] = df['course_students_enrolled'].fillna(df['course_students_enrolled'].median())\n",
    "\n",
    "df['Ratings'] = pd.to_numeric(df['Ratings'], errors='coerce')\n",
    "df['Ratings'] = df['Ratings'].fillna(df['Ratings'].median())\n",
    "\n",
    "df['Review Count'] = df['Review Count'].astype(str).str.replace(',', '', regex=False)\n",
    "df['Review Count'] = pd.to_numeric(df['Review Count'], errors='coerce')\n",
    "df['Review Count'] = df['Review Count'].fillna(df['Review Count'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60affc8b",
   "metadata": {},
   "source": [
    "Combining Text for TF-IDF : Implementation of BOW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5533d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = (\n",
    "    df['Title'] + \" \" +\n",
    "    df['Organization'] + \" \" +\n",
    "    df['Skills'] + \" \" +\n",
    "    df['course_description'] + \" \" +\n",
    "    df['Difficulty'] + \" \" +\n",
    "    df['Type'] + \" \" +\n",
    "    df['Duration']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b242b7",
   "metadata": {},
   "source": [
    "Tf-IDF for CBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vec.fit_transform(df['combined_text'])\n",
    "\n",
    "count_vec = CountVectorizer(stop_words='english')\n",
    "count_matrix = count_vec.fit_transform(df['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a481cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(matrix, metric=\"cosine\"):\n",
    "    if metric == \"cosine\":\n",
    "        return cosine_similarity(matrix)\n",
    "    elif metric == \"adjusted_cosine\":\n",
    "        # adjusted cosine = cosine similarity after subtracting mean per row\n",
    "        norm = matrix - matrix.mean(axis=1)\n",
    "        return cosine_similarity(np.array(norm))\n",
    "    elif metric == \"euclidean\":\n",
    "        return 1 / (1 + euclidean_distances(matrix))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid similarity metric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45907d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_matrices(metric):\n",
    "    return (\n",
    "        compute_similarity(tfidf_matrix, metric),\n",
    "        compute_similarity(count_matrix, metric),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b920f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_course_index(course_title, df, threshold=50):\n",
    "    titles = df['Title'].tolist()\n",
    "    match, score = process.extractOne(course_title, titles)\n",
    "    if score < threshold:\n",
    "        return None\n",
    "    return df[df['Title'] == match].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd0c0b",
   "metadata": {},
   "source": [
    "Recommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbf_recommend(course_title, df, sim_matrix, top_n=5):\n",
    "    idx = find_course_index(course_title, df)\n",
    "    if idx is None:\n",
    "        return \"Course not found!\"\n",
    "\n",
    "    sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "\n",
    "    return df.iloc[[i[0] for i in sim_scores]][[\n",
    "        'Title', 'Organization', 'Skills', 'Difficulty'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb07c9b",
   "metadata": {},
   "source": [
    "For Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60278f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= TF-IDF RESULTS =======================\n",
      "                                 Title                 Organization  \\\n",
      "115       learn sql basic data science  university california davis   \n",
      "14                ibm data engineering                          ibm   \n",
      "3                     ibm data science                          ibm   \n",
      "41         ibm data warehouse engineer                          ibm   \n",
      "369  applied data science data analyst                   databricks   \n",
      "\n",
      "                                                Skills    Difficulty  \n",
      "115  database sql data management data analysis big...      beginner  \n",
      "14   data management database database administrati...      beginner  \n",
      "3    python programming data science machine learni...      beginner  \n",
      "41   data management database administration databa...      beginner  \n",
      "369  machine learning machine learning algorithm al...  intermediate  \n",
      "\n",
      "==================== COUNTVECTORIZER RESULTS =====================\n",
      "                            Title                 Organization  \\\n",
      "3                ibm data science                          ibm   \n",
      "140   applied data science python          university michigan   \n",
      "115  learn sql basic data science  university california davis   \n",
      "14           ibm data engineering                          ibm   \n",
      "5                ibm data analyst                          ibm   \n",
      "\n",
      "                                                Skills    Difficulty  \n",
      "3    python programming data science machine learni...      beginner  \n",
      "140  python programming data analysis computer prog...  intermediate  \n",
      "115  database sql data management data analysis big...      beginner  \n",
      "14   data management database database administrati...      beginner  \n",
      "5    python programming microsoft excel data visual...      beginner  \n"
     ]
    }
   ],
   "source": [
    "course_title = input(\"Enter Course Title: \")\n",
    "metric_choice = input(\"Choose similarity (cosine / adjusted_cosine / euclidean): \").strip()\n",
    "\n",
    "tfidf_sim, count_sim = get_sim_matrices(metric_choice)\n",
    "\n",
    "print(\"\\n======================= TF-IDF RESULTS =======================\")\n",
    "print(cbf_recommend(course_title, df, tfidf_sim))\n",
    "\n",
    "print(\"\\n==================== COUNTVECTORIZER RESULTS =====================\")\n",
    "print(cbf_recommend(course_title, df, count_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54422ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ea05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0ebed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcb70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872b94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbee1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63fd02a1",
   "metadata": {},
   "source": [
    "Pickeling Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9beb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cbf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"df\": df,\n",
    "        \"tfidf_vec\": tfidf_vec,\n",
    "        \"tfidf_matrix\": tfidf_matrix,\n",
    "        \"count_vec\": count_vec,\n",
    "        \"count_matrix\": count_matrix\n",
    "    }, f)\n",
    "\n",
    "print(\" Model and data successfully saved as cbf_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
