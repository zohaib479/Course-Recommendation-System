{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af8656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz\n",
      "  Using cached thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
      "  Downloading rapidfuzz-3.14.3-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Using cached thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp313-cp313-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 907.7 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.5/1.5 MB 907.7 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.8/1.5 MB 642.6 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.8/1.5 MB 642.6 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.8/1.5 MB 642.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.5 MB 603.2 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 603.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 604.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 604.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 604.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 527.2 kB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, thefuzz\n",
      "\n",
      "   ---------------------------------------- 0/2 [rapidfuzz]\n",
      "   ---------------------------------------- 0/2 [rapidfuzz]\n",
      "   ---------------------------------------- 0/2 [rapidfuzz]\n",
      "   ---------------------------------------- 2/2 [thefuzz]\n",
      "\n",
      "Successfully installed rapidfuzz-3.14.3 thefuzz-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c645b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from thefuzz import process  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e22e665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c89f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a169f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \" \", text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # stopword remove\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]   # lemmatize\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34814d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/coursera_course_dataset_v3.csv\")\n",
    "df = df.drop(columns=['unnamed:_0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d984fa8",
   "metadata": {},
   "source": [
    "Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f36ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Title', 'Organization', 'Skills', 'course_description', 'Difficulty', 'Type', 'Duration']\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "    df[col] = df[col].str.replace(\"Ã‚\", \"\", regex=False).str.strip()\n",
    "    df[col] = df[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b847571",
   "metadata": {},
   "source": [
    "Numeric Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01c2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['course_students_enrolled'] = df['course_students_enrolled'].astype(str).str.replace(',', '', regex=False)\n",
    "df['course_students_enrolled'] = pd.to_numeric(df['course_students_enrolled'], errors='coerce')\n",
    "df['course_students_enrolled'] = df['course_students_enrolled'].fillna(df['course_students_enrolled'].median())\n",
    "\n",
    "df['Ratings'] = pd.to_numeric(df['Ratings'], errors='coerce')\n",
    "df['Ratings'] = df['Ratings'].fillna(df['Ratings'].median())\n",
    "\n",
    "df['Review Count'] = df['Review Count'].astype(str).str.replace(',', '', regex=False)\n",
    "df['Review Count'] = pd.to_numeric(df['Review Count'], errors='coerce')\n",
    "df['Review Count'] = df['Review Count'].fillna(df['Review Count'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60affc8b",
   "metadata": {},
   "source": [
    "Combining Text for TF-IDF : Implementation of BOW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5533d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = (\n",
    "    df['Title'] + \" \" +\n",
    "    df['Organization'] + \" \" +\n",
    "    df['Skills'] + \" \" +\n",
    "    df['course_description'] + \" \" +\n",
    "    df['Difficulty'] + \" \" +\n",
    "    df['Type'] + \" \" +\n",
    "    df['Duration']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b242b7",
   "metadata": {},
   "source": [
    "Tf-IDF for CBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c052338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['combined_text'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b920f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_course_index(course_title, df, threshold=50):\n",
    "    titles = df['Title'].tolist()\n",
    "    match, score = process.extractOne(course_title, titles)\n",
    "    if score < threshold:\n",
    "        return None\n",
    "    return df[df['Title'] == match].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd0c0b",
   "metadata": {},
   "source": [
    "Recommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1934e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbf_recommend(course_title, df, sim_matrix, top_n=5):\n",
    "    idx = find_course_index(course_title, df)\n",
    "    if idx is None:\n",
    "        return \"Course not found!\"\n",
    "\n",
    "    sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    \n",
    "    return df.iloc[[i[0] for i in sim_scores]][[\n",
    "        'Title', 'Organization', 'Skills', 'Difficulty'\n",
    "    ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb07c9b",
   "metadata": {},
   "source": [
    "For Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60278f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Content-Based Filtering Recommendations:\n",
      "                                  Title Organization  \\\n",
      "11    ibm full stack software developer          ibm   \n",
      "57       ibm applied devops engineering          ibm   \n",
      "9       ibm devops software engineering          ibm   \n",
      "59              ibm front end developer          ibm   \n",
      "50  ibm full stack javascript developer          ibm   \n",
      "\n",
      "                                               Skills    Difficulty  \n",
      "11  cloud computing python programming cloud appli...      beginner  \n",
      "57  devops software engineering cloud computing co...  intermediate  \n",
      "9   devops software engineering cloud computing co...      beginner  \n",
      "59  cloud application software engineering compute...      beginner  \n",
      "50  software engineering computer programming soft...      beginner  \n"
     ]
    }
   ],
   "source": [
    "course_title = \"Back End\"\n",
    "\n",
    "print(\"-> Content-Based Filtering Recommendations:\")\n",
    "print(cbf_recommend(course_title, df, cosine_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54422ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
